<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="">
  <meta name="keyword" content="hexo-theme">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      Apache Kafka Notes(2021/07/08 updated 1/9) | Daily Growing
    
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  
<link rel="stylesheet" href="/css/style.css">

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
  
  
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  
  
    
<script src="/js/local-search.js"></script>


<meta name="generator" content="Hexo 7.0.0"></head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>
  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>Daily Growing</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/series/" class="item-link">Series</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
      
        <li class="menu-item menu-item-search right-list">
    <a role="button" class="popup-trigger">
        <i class="fa fa-search fa-fw"></i>
    </a>
</li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/series/" class="menu-link">Series</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
    
      <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
            <span class="search-icon">
                <i class="fa fa-search"></i>
            </span>
            <div class="search-input-container">
                <input autocomplete="off" autocapitalize="off"
                    placeholder="Please enter your keyword(s) to search." spellcheck="false"
                    type="search" class="search-input">
            </div>
            <span class="popup-btn-close">
                <i class="fa fa-times-circle"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>
    
  </div>
</header>

    <div id="article-banner">
  <h2>Apache Kafka Notes(2021/07/08 updated 1/9)</h2>
  <p class="post-date">2021-07-08</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><p>Apache Kafka is an open-source distributed event streaming platform for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications. Notes by Kafka official website.</p>
<span id="more"></span>
<h1 id="1-GETTING-STARTED"><a href="#1-GETTING-STARTED" class="headerlink" title="1. GETTING STARTED"></a>1. GETTING STARTED</h1><h2 id="1-1-Introduction"><a href="#1-1-Introduction" class="headerlink" title="1.1 Introduction"></a>1.1 Introduction</h2><p>Kafka combines three key capabilities so you can implement your use cases for event streaming end-to-end with a single battle-tested solution:</p>
<ul>
<li>To publish (write) and subscribe to (read) streams of events, including continuous import&#x2F;export of your data from other systems.</li>
<li>To store streams of events durably and reliably for as long as you want.</li>
<li>To process streams of events as they occur or retrospectively.</li>
</ul>
<p>And all this functionality is provided in a distributed, highly scalable, elastic, fault-tolerant, and secure manner. Kafka can be deployed on bare-metal hardware, virtual machines, and containers, and on-premises as well as in the cloud.</p>
<h3 id="How-does-Kafka-work"><a href="#How-does-Kafka-work" class="headerlink" title="How does Kafka work"></a>How does Kafka work</h3><p>Kafka is a distributed system consisting of servers and clients that communicate via a high-performance TCP network protocol. </p>
<p><strong>Servers</strong>: Kafka is run as a cluster of one or more servers that can span multiple datacenters or cloud regions. Some of these servers form the storage layer, called the brokers. Other servers run Kafka Connect to continuously import and export data as event streams to integrate Kafka with your existing systems such as relational databases as well as other Kafka clusters. To let you implement mission-critical use cases, a Kafka cluster is highly scalable and fault-tolerant: if any of its servers fails, the other servers will take over their work to ensure continuous operations without any data loss.</p>
<p><strong>Clients</strong>: They allow you to write distributed applications and microservices that read, write, and process streams of events in parallel, at scale, and in a fault-tolerant manner even in the case of network problems or machine failures. Kafka ships with some such clients included, which are augmented by dozens of clients provided by the Kafka community: clients are available for Java and Scala including the higher-level Kafka Streams library, for Go, Python, C&#x2F;C++, and many other programming languages as well as REST APIs.</p>
<h3 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h3><p>An <strong>event</strong> is also called record or message in the documentation. When you read or write data to Kafka, you do this in the form of events. Conceptually, an event has a key, value, timestamp, and optional metadata headers.</p>
<p><strong>Producers</strong> are those client applications that publish (write) events to Kafka, and <strong>consumers</strong> are those that subscribe to (read and process) these events. In Kafka, producers and consumers are fully decoupled and agnostic of each other, which is a key design element to achieve the high scalability that Kafka is known for.</p>
<p>Events are organized and durably stored in <strong>topics</strong>. Very simplified, a topic is similar to a folder in a filesystem, and the events are the files in that folder. An example topic name could be “payments”. Topics in Kafka are always multi-producer and multi-subscriber: a topic can have zero, one, or many producers that write events to it, as well as zero, one, or many consumers that subscribe to these events. Events in a topic can be read as often as needed—unlike traditional messaging systems, events are not deleted after consumption. Instead, you define for how long Kafka should retain your events through a per-topic configuration setting, after which old events will be discarded. Kafka’s performance is effectively constant with respect to data size, so storing data for a long time is perfectly fine.</p>
<p>Topics are <strong>partitioned</strong>, meaning a topic is spread over a number of “buckets” located on different Kafka brokers. This distributed placement of your data is very important for scalability because it allows client applications to both read and write the data from&#x2F;to many brokers at the same time.</p>
<p><img src="/images/kafka/streams-and-tables-p1_p4.png" alt="streams-and-tables-p1_p4"></p>
<p>To make your data fault-tolerant and highly-available, every topic can be <strong>replicated</strong>, even across geo-regions or datacenters, so that there are always multiple brokers that have a copy of the data just in case things go wrong, you want to do maintenance on the brokers, and so on. A common production setting is a replication factor of 3, i.e., there will always be three copies of your data. This replication is performed at the level of topic-partitions.</p>
<h2 id="1-2-Use-Cases"><a href="#1-2-Use-Cases" class="headerlink" title="1.2 Use Cases"></a>1.2 Use Cases</h2><ul>
<li>Messaging<br>In this domain Kafka is comparable to traditional messaging systems such as ActiveMQ or RabbitMQ.</li>
<li>Website Activity Tracking<br>The original use case for Kafka was to be able to rebuild a user activity tracking pipeline as a set of real-time publish-subscribe feeds. This means site activity (page views, searches, or other actions users may take) is published to central topics with one topic per activity type.</li>
<li>Metrics</li>
<li>Log Aggregation</li>
<li>Stream Processing</li>
<li>Event Sourcing</li>
<li>Commit Log</li>
</ul>
<h2 id="1-3-Quick-Start"><a href="#1-3-Quick-Start" class="headerlink" title="1.3 Quick Start"></a>1.3 Quick Start</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ tar -xzf kafka_2.13-2.8.0.tgz</span><br><span class="line">$ <span class="built_in">cd</span> kafka_2.13-2.8.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. START THE KAFKA ENVIRONMENT</span></span><br><span class="line"><span class="comment"># Start the ZooKeeper service</span></span><br><span class="line"><span class="comment"># Note: Soon, ZooKeeper will no longer be required by Apache Kafka.</span></span><br><span class="line">$ bin/zookeeper-server-start.sh config/zookeeper.properties</span><br><span class="line"><span class="comment"># Start the Kafka broker service</span></span><br><span class="line">$ bin/kafka-server-start.sh config/server.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. CREATE A TOPIC TO STORE YOUR EVENTS</span></span><br><span class="line"><span class="comment"># Before you can write your first events, you must create a topic.</span></span><br><span class="line">$ bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. WRITE SOME EVENTS INTO THE TOPIC</span></span><br><span class="line">$ bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092</span><br><span class="line">This is my first event</span><br><span class="line">This is my second event</span><br><span class="line"><span class="comment"># You can stop the producer client with Ctrl-C at any time.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. READ THE EVENTS</span></span><br><span class="line"><span class="comment"># Open another terminal session and run the console consumer client to read the events you just created:</span></span><br><span class="line">$ bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092</span><br><span class="line">This is my first event</span><br><span class="line">This is my second event</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Feel free to experiment: for example, switch back to your producer terminal (previous step) to write additional events, and see how the events immediately show up in your consumer terminal.</p>
</blockquote>
<blockquote>
<p>Because events are durably stored in Kafka, they can be read as many times and by as many consumers as you want. You can easily verify this by opening yet another terminal session and re-running the previous command again.</p>
</blockquote>
<ol start="6">
<li><p>IMPORT&#x2F;EXPORT YOUR DATA AS STREAMS OF EVENTS WITH KAFKA CONNECT</p>
<p> Kafka Connect allows you to continuously ingest data from external systems into Kafka, and vice versa. It is thus very easy to integrate existing systems with Kafka. </p>
</li>
<li><p>PROCESS YOUR EVENTS WITH KAFKA STREAMS<br>Once your data is stored in Kafka as events, you can process the data with the Kafka Streams client library for Java&#x2F;Scala. It allows you to implement mission-critical real-time applications and microservices, where the input and&#x2F;or output data is stored in Kafka topics.</p>
<p>Here’s how one would implement the popular “WordCount” algorithm:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">KStream&lt;String, String&gt; textLines = builder.stream(<span class="string">&quot;quickstart-events&quot;</span>);</span><br><span class="line"> KTable&lt;String, Long&gt; wordCounts = textLines</span><br><span class="line">         .flatMapValues(line -&gt; Arrays.asList(line.toLowerCase().split(<span class="string">&quot; &quot;</span>)))</span><br><span class="line">         .groupBy((keyIgnored, word) -&gt; word)</span><br><span class="line">         .count();</span><br><span class="line"> wordCounts.toStream().to(<span class="string">&quot;output-topic&quot;</span>, Produced.with(Serdes.String(), Serdes.Long()));</span><br></pre></td></tr></table></figure></li>
<li><p>TERMINATE THE KAFKA ENVIRONMENT</p>
<ol>
<li>Stop the producer and consumer clients with Ctrl-C, if you haven’t done so already.</li>
<li>Stop the Kafka broker with Ctrl-C.</li>
<li>Lastly, stop the ZooKeeper server with Ctrl-C.</li>
<li> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># If you also want to delete any data of your local Kafka environment including any events you have created along the way, run the command:</span></span><br><span class="line">$ <span class="built_in">rm</span> -rf /tmp/kafka-logs /tmp/zookeeper</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="1-4-Ecosystem"><a href="#1-4-Ecosystem" class="headerlink" title="1.4 Ecosystem"></a>1.4 Ecosystem</h2><p><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">Here is a list of tools about integrate with Kafka outside the main distribution</a></p>
<h1 id="2-APIS"><a href="#2-APIS" class="headerlink" title="2. APIS"></a>2. APIS</h1><h1 id="8-KAFKA-CONNECT"><a href="#8-KAFKA-CONNECT" class="headerlink" title="8. KAFKA CONNECT"></a>8. KAFKA CONNECT</h1><h2 id="8-1-Overview"><a href="#8-1-Overview" class="headerlink" title="8.1 Overview"></a>8.1 Overview</h2><p>Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems. It makes it simple to quickly define connectors that move large collections of data into and out of Kafka. Kafka Connect can ingest entire databases or collect metrics from all your application servers into Kafka topics, making the data available for stream processing with low latency. </p>
<p>Kafka Connect features include:</p>
<ul>
<li><strong>A common framework for Kafka connectors</strong> - Kafka Connect standardizes integration of other data systems with Kafka, simplifying connector development, deployment, and management<br>Distributed and standalone modes - scale up to a large, centrally managed service supporting an entire organization or scale down to development, testing, and small production deployments</li>
<li><strong>REST interface</strong> - submit and manage connectors to your Kafka Connect cluster via an easy to use REST API</li>
<li><strong>Automatic offset management</strong> - with just a little information from connectors, Kafka Connect can manage the offset commit process automatically so connector developers do not need to worry about this error prone part of connector development</li>
<li><strong>Distributed and scalable by default</strong> - Kafka Connect builds on the existing group management protocol. More workers can be added to scale up a Kafka Connect cluster.</li>
<li><strong>Streaming&#x2F;batch integration</strong> - leveraging Kafka’s existing capabilities, Kafka Connect is an ideal solution for bridging streaming and batch data systems</li>
</ul>
<h2 id="8-2-User-Guide"><a href="#8-2-User-Guide" class="headerlink" title="8.2 User Guide"></a>8.2 User Guide</h2></section>
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#Kafka" >
    <span class="tag-code">Kafka</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2021/06/21/lendi-salesforce/">
        <span class="nav-arrow">← </span>
        
          Salesforce notes(2021/06/21 updated 1/26)
        
      </a>
    
    
      <a class="nav-right" href="/2021/07/09/docker/">
        
          Docker Notes(2021/07/09 updated)
        
        <span class="nav-arrow"> →</span>
      </a>
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
    <!-- 二维码 END -->
    
      <!-- Utterances START -->
      <div id="utterances"></div>
      <script src="https://utteranc.es/client.js"
        repo=""
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async></script>    
      <!-- Utterances END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#1-GETTING-STARTED"><span class="toc-nav-text">1. GETTING STARTED</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-1-Introduction"><span class="toc-nav-text">1.1 Introduction</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#How-does-Kafka-work"><span class="toc-nav-text">How does Kafka work</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Concepts"><span class="toc-nav-text">Concepts</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-2-Use-Cases"><span class="toc-nav-text">1.2 Use Cases</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-3-Quick-Start"><span class="toc-nav-text">1.3 Quick Start</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-4-Ecosystem"><span class="toc-nav-text">1.4 Ecosystem</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#2-APIS"><span class="toc-nav-text">2. APIS</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#8-KAFKA-CONNECT"><span class="toc-nav-text">8. KAFKA CONNECT</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#8-1-Overview"><span class="toc-nav-text">8.1 Overview</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#8-2-User-Guide"><span class="toc-nav-text">8.2 User Guide</span></a></li></ol></li></ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://yoursite.com/2021/07/08/kafka/';
    var banner = ''
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

    // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', '/css/images/error_icon.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== '/css/images/error_icon.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()

        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })
  })();
</script>







    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2024 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      hljs.configure({useBR: true});
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->


<script src="/js/script.js"></script>


  </body>
</html>